// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: org/project_planton/provider/kubernetes/kuberneteskafka/v1/spec.proto

package kuberneteskafkav1

import (
	_ "buf.build/gen/go/bufbuild/protovalidate/protocolbuffers/go/buf/validate"
	kubernetes "github.com/project-planton/project-planton/apis/org/project_planton/shared/kubernetes"
	_ "github.com/project-planton/project-planton/apis/org/project_planton/shared/options"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	descriptorpb "google.golang.org/protobuf/types/descriptorpb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// **KubernetesKafkaSpec** defines the configuration for deploying Apache Kafka on a Kubernetes cluster.
// This message includes specifications for Kafka topics, broker containers, Zookeeper containers, schema registry,
// ingress settings, and the option to deploy a Kafka UI.
// By configuring these parameters, you can set up a Kafka cluster tailored to your application's needs, including
// resource allocation, data persistence, and external access.
type KubernetesKafkaSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A list of Kafka topics to be created in the Kafka cluster.
	KafkaTopics []*KafkaTopic `protobuf:"bytes,1,rep,name=kafka_topics,json=kafkaTopics,proto3" json:"kafka_topics,omitempty"`
	// The specifications for the Kafka broker containers.
	BrokerContainer *KubernetesKafkaBrokerContainer `protobuf:"bytes,2,opt,name=broker_container,json=brokerContainer,proto3" json:"broker_container,omitempty"`
	// The specifications for the Zookeeper containers.
	ZookeeperContainer *KubernetesKafkaZookeeperContainer `protobuf:"bytes,3,opt,name=zookeeper_container,json=zookeeperContainer,proto3" json:"zookeeper_container,omitempty"`
	// The specifications for the Schema Registry containers.
	SchemaRegistryContainer *KubernetesKafkaSchemaRegistryContainer `protobuf:"bytes,4,opt,name=schema_registry_container,json=schemaRegistryContainer,proto3" json:"schema_registry_container,omitempty"`
	// The ingress configuration for the Kafka deployment.
	Ingress *kubernetes.IngressSpec `protobuf:"bytes,5,opt,name=ingress,proto3" json:"ingress,omitempty"`
	// A flag to toggle the deployment of the Kafka UI component.
	IsDeployKafkaUi bool `protobuf:"varint,6,opt,name=is_deploy_kafka_ui,json=isDeployKafkaUi,proto3" json:"is_deploy_kafka_ui,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *KubernetesKafkaSpec) Reset() {
	*x = KubernetesKafkaSpec{}
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KubernetesKafkaSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KubernetesKafkaSpec) ProtoMessage() {}

func (x *KubernetesKafkaSpec) ProtoReflect() protoreflect.Message {
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KubernetesKafkaSpec.ProtoReflect.Descriptor instead.
func (*KubernetesKafkaSpec) Descriptor() ([]byte, []int) {
	return file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescGZIP(), []int{0}
}

func (x *KubernetesKafkaSpec) GetKafkaTopics() []*KafkaTopic {
	if x != nil {
		return x.KafkaTopics
	}
	return nil
}

func (x *KubernetesKafkaSpec) GetBrokerContainer() *KubernetesKafkaBrokerContainer {
	if x != nil {
		return x.BrokerContainer
	}
	return nil
}

func (x *KubernetesKafkaSpec) GetZookeeperContainer() *KubernetesKafkaZookeeperContainer {
	if x != nil {
		return x.ZookeeperContainer
	}
	return nil
}

func (x *KubernetesKafkaSpec) GetSchemaRegistryContainer() *KubernetesKafkaSchemaRegistryContainer {
	if x != nil {
		return x.SchemaRegistryContainer
	}
	return nil
}

func (x *KubernetesKafkaSpec) GetIngress() *kubernetes.IngressSpec {
	if x != nil {
		return x.Ingress
	}
	return nil
}

func (x *KubernetesKafkaSpec) GetIsDeployKafkaUi() bool {
	if x != nil {
		return x.IsDeployKafkaUi
	}
	return false
}

// **KubernetesKafkaBrokerContainer** specifies the configuration for the Kafka broker containers.
// It includes settings such as the number of replicas, resource allocations, and disk size.
// Proper configuration ensures optimal performance and data reliability for your Kafka brokers.
type KubernetesKafkaBrokerContainer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of Kafka brokers to deploy.
	// Defaults to 1 if the client sets the value to 0.
	// Recommended default value is 1.
	Replicas int32 `protobuf:"varint,1,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// The CPU and memory resources allocated to the Kafka broker containers.
	Resources *kubernetes.ContainerResources `protobuf:"bytes,2,opt,name=resources,proto3" json:"resources,omitempty"`
	// The size of the disk to be attached to each broker instance (e.g., "30Gi").
	// A default value is set if not provided by the client.
	DiskSize      string `protobuf:"bytes,3,opt,name=disk_size,json=diskSize,proto3" json:"disk_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KubernetesKafkaBrokerContainer) Reset() {
	*x = KubernetesKafkaBrokerContainer{}
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KubernetesKafkaBrokerContainer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KubernetesKafkaBrokerContainer) ProtoMessage() {}

func (x *KubernetesKafkaBrokerContainer) ProtoReflect() protoreflect.Message {
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KubernetesKafkaBrokerContainer.ProtoReflect.Descriptor instead.
func (*KubernetesKafkaBrokerContainer) Descriptor() ([]byte, []int) {
	return file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescGZIP(), []int{1}
}

func (x *KubernetesKafkaBrokerContainer) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *KubernetesKafkaBrokerContainer) GetResources() *kubernetes.ContainerResources {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *KubernetesKafkaBrokerContainer) GetDiskSize() string {
	if x != nil {
		return x.DiskSize
	}
	return ""
}

// **KubernetesKafkaZookeeperContainer** specifies the configuration for the Zookeeper containers.
// Zookeeper is required for Kafka cluster management and coordination.
// Proper configuration ensures high availability and reliability of your Kafka cluster.
type KubernetesKafkaZookeeperContainer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of Zookeeper container replicas.
	// Zookeeper requires at least 3 replicas for high availability (HA) mode.
	// Zookeeper uses the Raft consensus algorithm; refer to https://raft.github.io/ for more information on how replica
	// count affects availability.
	Replicas int32 `protobuf:"varint,1,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// The CPU and memory resources allocated to the Zookeeper containers.
	Resources *kubernetes.ContainerResources `protobuf:"bytes,2,opt,name=resources,proto3" json:"resources,omitempty"`
	// The size of the disk to be attached to each Zookeeper instance (e.g., "30Gi").
	// A default value is set if not provided by the client.
	DiskSize      string `protobuf:"bytes,3,opt,name=disk_size,json=diskSize,proto3" json:"disk_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KubernetesKafkaZookeeperContainer) Reset() {
	*x = KubernetesKafkaZookeeperContainer{}
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KubernetesKafkaZookeeperContainer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KubernetesKafkaZookeeperContainer) ProtoMessage() {}

func (x *KubernetesKafkaZookeeperContainer) ProtoReflect() protoreflect.Message {
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KubernetesKafkaZookeeperContainer.ProtoReflect.Descriptor instead.
func (*KubernetesKafkaZookeeperContainer) Descriptor() ([]byte, []int) {
	return file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescGZIP(), []int{2}
}

func (x *KubernetesKafkaZookeeperContainer) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *KubernetesKafkaZookeeperContainer) GetResources() *kubernetes.ContainerResources {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *KubernetesKafkaZookeeperContainer) GetDiskSize() string {
	if x != nil {
		return x.DiskSize
	}
	return ""
}

// **KubernetesKafkaSchemaRegistryContainer** specifies the configuration for the Schema Registry containers.
// The Schema Registry provides a serving layer for your metadata, allowing data producers and consumers to evolve independently.
type KubernetesKafkaSchemaRegistryContainer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A flag to control whether the Schema Registry is created for the Kafka deployment.
	// Defaults to `false`.
	IsEnabled bool `protobuf:"varint,1,opt,name=is_enabled,json=isEnabled,proto3" json:"is_enabled,omitempty"`
	// The number of Schema Registry replicas.
	// Recommended default value is "1".
	// This value has no effect if `is_enabled` is set to `false`.
	Replicas int32 `protobuf:"varint,2,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// The CPU and memory resources allocated to the Schema Registry containers.
	Resources     *kubernetes.ContainerResources `protobuf:"bytes,3,opt,name=resources,proto3" json:"resources,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KubernetesKafkaSchemaRegistryContainer) Reset() {
	*x = KubernetesKafkaSchemaRegistryContainer{}
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KubernetesKafkaSchemaRegistryContainer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KubernetesKafkaSchemaRegistryContainer) ProtoMessage() {}

func (x *KubernetesKafkaSchemaRegistryContainer) ProtoReflect() protoreflect.Message {
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KubernetesKafkaSchemaRegistryContainer.ProtoReflect.Descriptor instead.
func (*KubernetesKafkaSchemaRegistryContainer) Descriptor() ([]byte, []int) {
	return file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescGZIP(), []int{3}
}

func (x *KubernetesKafkaSchemaRegistryContainer) GetIsEnabled() bool {
	if x != nil {
		return x.IsEnabled
	}
	return false
}

func (x *KubernetesKafkaSchemaRegistryContainer) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *KubernetesKafkaSchemaRegistryContainer) GetResources() *kubernetes.ContainerResources {
	if x != nil {
		return x.Resources
	}
	return nil
}

// **KafkaTopic** represents a Kafka topic to be created in the Kafka cluster.
// It includes configurations such as the topic name, number of partitions, replicas, and additional configurations.
type KafkaTopic struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the Kafka topic.
	// Must be between 1 and 249 characters in length.
	// The name must start and end with an alphanumeric character, can contain alphanumeric characters, '.', '_', and '-'.
	// Must not contain '..' or non-ASCII characters.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// The number of partitions for the topic.
	// Recommended default is 1.
	Partitions *int32 `protobuf:"varint,2,opt,name=partitions,proto3,oneof" json:"partitions,omitempty"`
	// The number of replicas for the topic.
	// Recommended default is 1.
	Replicas *int32 `protobuf:"varint,3,opt,name=replicas,proto3,oneof" json:"replicas,omitempty"`
	// Additional configuration for the Kafka topic.
	// If not provided, default values will be set.
	// For example, the default `delete.policy` is `delete`, but it can be set to `compact`.
	Config        map[string]string `protobuf:"bytes,4,rep,name=config,proto3" json:"config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KafkaTopic) Reset() {
	*x = KafkaTopic{}
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaTopic) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaTopic) ProtoMessage() {}

func (x *KafkaTopic) ProtoReflect() protoreflect.Message {
	mi := &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaTopic.ProtoReflect.Descriptor instead.
func (*KafkaTopic) Descriptor() ([]byte, []int) {
	return file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescGZIP(), []int{4}
}

func (x *KafkaTopic) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *KafkaTopic) GetPartitions() int32 {
	if x != nil && x.Partitions != nil {
		return *x.Partitions
	}
	return 0
}

func (x *KafkaTopic) GetReplicas() int32 {
	if x != nil && x.Replicas != nil {
		return *x.Replicas
	}
	return 0
}

func (x *KafkaTopic) GetConfig() map[string]string {
	if x != nil {
		return x.Config
	}
	return nil
}

var file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_extTypes = []protoimpl.ExtensionInfo{
	{
		ExtendedType:  (*descriptorpb.FieldOptions)(nil),
		ExtensionType: (*KubernetesKafkaBrokerContainer)(nil),
		Field:         524001,
		Name:          "org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.default_broker_container",
		Tag:           "bytes,524001,opt,name=default_broker_container",
		Filename:      "org/project_planton/provider/kubernetes/kuberneteskafka/v1/spec.proto",
	},
	{
		ExtendedType:  (*descriptorpb.FieldOptions)(nil),
		ExtensionType: (*KubernetesKafkaZookeeperContainer)(nil),
		Field:         524002,
		Name:          "org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.default_zookeeper_container",
		Tag:           "bytes,524002,opt,name=default_zookeeper_container",
		Filename:      "org/project_planton/provider/kubernetes/kuberneteskafka/v1/spec.proto",
	},
}

// Extension fields to descriptorpb.FieldOptions.
var (
	// optional org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaBrokerContainer default_broker_container = 524001;
	E_DefaultBrokerContainer = &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_extTypes[0]
	// optional org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaZookeeperContainer default_zookeeper_container = 524002;
	E_DefaultZookeeperContainer = &file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_extTypes[1]
)

var File_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto protoreflect.FileDescriptor

const file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDesc = "" +
	"\n" +
	"Eorg/project_planton/provider/kubernetes/kuberneteskafka/v1/spec.proto\x12Corg.project_planton.provider.kubernetes.workload.kuberneteskafka.v1\x1a\x1bbuf/validate/validate.proto\x1a google/protobuf/descriptor.proto\x1a6org/project_planton/shared/kubernetes/kubernetes.proto\x1a3org/project_planton/shared/kubernetes/options.proto\x1a0org/project_planton/shared/options/options.proto\"\xbb\x06\n" +
	"\x13KubernetesKafkaSpec\x12r\n" +
	"\fkafka_topics\x18\x01 \x03(\v2O.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KafkaTopicR\vkafkaTopics\x12\xba\x01\n" +
	"\x10broker_container\x18\x02 \x01(\v2c.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaBrokerContainerB*\x8a\xee\xff\x01%\b\x01\x12\x1c\n" +
	"\f\n" +
	"\x051000m\x12\x031Gi\x12\f\n" +
	"\x0350m\x12\x05100Mi\x1a\x031GiR\x0fbrokerContainer\x12\xc3\x01\n" +
	"\x13zookeeper_container\x18\x03 \x01(\v2f.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaZookeeperContainerB*\x92\xee\xff\x01%\b\x01\x12\x1c\n" +
	"\f\n" +
	"\x051000m\x12\x031Gi\x12\f\n" +
	"\x0350m\x12\x05100Mi\x1a\x031GiR\x12zookeeperContainer\x12\xa7\x01\n" +
	"\x19schema_registry_container\x18\x04 \x01(\v2k.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSchemaRegistryContainerR\x17schemaRegistryContainer\x12L\n" +
	"\aingress\x18\x05 \x01(\v22.org.project_planton.shared.kubernetes.IngressSpecR\aingress\x125\n" +
	"\x12is_deploy_kafka_ui\x18\x06 \x01(\bB\b\x92\xa6\x1d\x04trueR\x0fisDeployKafkaUi\"\xd9\x02\n" +
	"\x1eKubernetesKafkaBrokerContainer\x12\x1a\n" +
	"\breplicas\x18\x01 \x01(\x05R\breplicas\x12W\n" +
	"\tresources\x18\x02 \x01(\v29.org.project_planton.shared.kubernetes.ContainerResourcesR\tresources\x12\xc1\x01\n" +
	"\tdisk_size\x18\x03 \x01(\tB\xa3\x01\xbaH\x9f\x01\xba\x01\x9b\x01\n" +
	"&spec.broker_container.disk_size.format\x12\x1aDisk size value is invalid\x1aUthis.matches('^\\\\d+(\\\\.\\\\d+)?\\\\s?(Ki|Mi|Gi|Ti|Pi|Ei|K|M|G|T|P|E)$') && size(this) > 0R\bdiskSize\"\xdc\x02\n" +
	"!KubernetesKafkaZookeeperContainer\x12\x1a\n" +
	"\breplicas\x18\x01 \x01(\x05R\breplicas\x12W\n" +
	"\tresources\x18\x02 \x01(\v29.org.project_planton.shared.kubernetes.ContainerResourcesR\tresources\x12\xc1\x01\n" +
	"\tdisk_size\x18\x03 \x01(\tB\xa3\x01\xbaH\x9f\x01\xba\x01\x9b\x01\n" +
	"&spec.broker_container.disk_size.format\x12\x1aDisk size value is invalid\x1aUthis.matches('^\\\\d+(\\\\.\\\\d+)?\\\\s?(Ki|Mi|Gi|Ti|Pi|Ei|K|M|G|T|P|E)$') && size(this) > 0R\bdiskSize\"\xe6\x01\n" +
	"&KubernetesKafkaSchemaRegistryContainer\x12\x1d\n" +
	"\n" +
	"is_enabled\x18\x01 \x01(\bR\tisEnabled\x12!\n" +
	"\breplicas\x18\x02 \x01(\x05B\x05\x92\xa6\x1d\x011R\breplicas\x12z\n" +
	"\tresources\x18\x03 \x01(\v29.org.project_planton.shared.kubernetes.ContainerResourcesB!\xba\xfb\xa4\x02\x1c\n" +
	"\f\n" +
	"\x051000m\x12\x031Gi\x12\f\n" +
	"\x0350m\x12\x05100MiR\tresources\"\x97\t\n" +
	"\n" +
	"KafkaTopic\x12\x93\x04\n" +
	"\x04name\x18\x01 \x01(\tB\xfe\x03\xbaH\xfa\x03\xba\x01e\n" +
	"\x15topic.name.startswith\x12+Should start with an alphanumeric character\x1a\x1fthis.matches('^[a-zA-Z0-9].*$')\xba\x01v\n" +
	"\x10topic.name.chars\x12?Only alphanumeric and ('.', '_' and '-') characters are allowed\x1a!this.matches('^[a-zA-Z0-9._-]+$')\xba\x01H\n" +
	"\x19topic.name.no_double_dots\x12\x15Must not contain '..'\x1a\x14!this.contains('..')\xba\x01^\n" +
	"\x15topic.name.ascii_only\x12%Must not contain non-ASCII characters\x1a\x1ethis.matches('^[\\x00-\\x7F]+$')\xba\x01`\n" +
	"\x13topic.name.endswith\x12)Should end with an alphanumeric character\x1a\x1ethis.matches('.*[a-zA-Z0-9]$')\xc8\x01\x01r\x05\x10\x01\x18\xf9\x01R\x04name\x12*\n" +
	"\n" +
	"partitions\x18\x02 \x01(\x05B\x05\x8a\xa6\x1d\x011H\x00R\n" +
	"partitions\x88\x01\x01\x12&\n" +
	"\breplicas\x18\x03 \x01(\x05B\x05\x8a\xa6\x1d\x011H\x01R\breplicas\x88\x01\x01\x12\xc7\x03\n" +
	"\x06config\x18\x04 \x03(\v2[.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KafkaTopic.ConfigEntryB\xd1\x02\x9a\xa6\x1d\x18\n" +
	"\x0ecleanup.policy\x12\x06delete\x9a\xa6\x1d\x1f\n" +
	"\x13delete.retention.ms\x12\b86400000\x9a\xa6\x1d\x1c\n" +
	"\x11max.message.bytes\x12\a2097164\x9a\xa6\x1d:\n" +
	"#message.timestamp.difference.max.ms\x12\x139223372036854775807\x9a\xa6\x1d$\n" +
	"\x16message.timestamp.type\x12\n" +
	"CreateTime\x9a\xa6\x1d\x18\n" +
	"\x13min.insync.replicas\x12\x011\x9a\xa6\x1d\x15\n" +
	"\x0fretention.bytes\x12\x02-1\x9a\xa6\x1d\x19\n" +
	"\fretention.ms\x12\t604800000\x9a\xa6\x1d\x1b\n" +
	"\rsegment.bytes\x12\n" +
	"1073741824\x9a\xa6\x1d\x17\n" +
	"\n" +
	"segment.ms\x12\t604800000R\x06config\x1a9\n" +
	"\vConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01B\r\n" +
	"\v_partitionsB\v\n" +
	"\t_replicas:\xbe\x01\n" +
	"\x18default_broker_container\x12\x1d.google.protobuf.FieldOptions\x18\xe1\xfd\x1f \x01(\v2c.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaBrokerContainerR\x16defaultBrokerContainer:\xc7\x01\n" +
	"\x1bdefault_zookeeper_container\x12\x1d.google.protobuf.FieldOptions\x18\xe2\xfd\x1f \x01(\v2f.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaZookeeperContainerR\x19defaultZookeeperContainerB\x83\x04\n" +
	"Gcom.org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1B\tSpecProtoP\x01Z|github.com/project-planton/project-planton/apis/org/project_planton/provider/kubernetes/kuberneteskafka/v1;kuberneteskafkav1\xa2\x02\x06OPPKWK\xaa\x02BOrg.ProjectPlanton.Provider.Kubernetes.Workload.Kuberneteskafka.V1\xca\x02BOrg\\ProjectPlanton\\Provider\\Kubernetes\\Workload\\Kuberneteskafka\\V1\xe2\x02NOrg\\ProjectPlanton\\Provider\\Kubernetes\\Workload\\Kuberneteskafka\\V1\\GPBMetadata\xea\x02HOrg::ProjectPlanton::Provider::Kubernetes::Workload::Kuberneteskafka::V1b\x06proto3"

var (
	file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescOnce sync.Once
	file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescData []byte
)

func file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescGZIP() []byte {
	file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescOnce.Do(func() {
		file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDesc), len(file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDesc)))
	})
	return file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDescData
}

var file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes = make([]protoimpl.MessageInfo, 6)
var file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_goTypes = []any{
	(*KubernetesKafkaSpec)(nil),                    // 0: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSpec
	(*KubernetesKafkaBrokerContainer)(nil),         // 1: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaBrokerContainer
	(*KubernetesKafkaZookeeperContainer)(nil),      // 2: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaZookeeperContainer
	(*KubernetesKafkaSchemaRegistryContainer)(nil), // 3: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSchemaRegistryContainer
	(*KafkaTopic)(nil),                             // 4: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KafkaTopic
	nil,                                            // 5: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KafkaTopic.ConfigEntry
	(*kubernetes.IngressSpec)(nil),                 // 6: org.project_planton.shared.kubernetes.IngressSpec
	(*kubernetes.ContainerResources)(nil),          // 7: org.project_planton.shared.kubernetes.ContainerResources
	(*descriptorpb.FieldOptions)(nil),              // 8: google.protobuf.FieldOptions
}
var file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_depIdxs = []int32{
	4,  // 0: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSpec.kafka_topics:type_name -> org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KafkaTopic
	1,  // 1: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSpec.broker_container:type_name -> org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaBrokerContainer
	2,  // 2: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSpec.zookeeper_container:type_name -> org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaZookeeperContainer
	3,  // 3: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSpec.schema_registry_container:type_name -> org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSchemaRegistryContainer
	6,  // 4: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSpec.ingress:type_name -> org.project_planton.shared.kubernetes.IngressSpec
	7,  // 5: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaBrokerContainer.resources:type_name -> org.project_planton.shared.kubernetes.ContainerResources
	7,  // 6: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaZookeeperContainer.resources:type_name -> org.project_planton.shared.kubernetes.ContainerResources
	7,  // 7: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaSchemaRegistryContainer.resources:type_name -> org.project_planton.shared.kubernetes.ContainerResources
	5,  // 8: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KafkaTopic.config:type_name -> org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KafkaTopic.ConfigEntry
	8,  // 9: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.default_broker_container:extendee -> google.protobuf.FieldOptions
	8,  // 10: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.default_zookeeper_container:extendee -> google.protobuf.FieldOptions
	1,  // 11: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.default_broker_container:type_name -> org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaBrokerContainer
	2,  // 12: org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.default_zookeeper_container:type_name -> org.project_planton.provider.kubernetes.workload.kuberneteskafka.v1.KubernetesKafkaZookeeperContainer
	13, // [13:13] is the sub-list for method output_type
	13, // [13:13] is the sub-list for method input_type
	11, // [11:13] is the sub-list for extension type_name
	9,  // [9:11] is the sub-list for extension extendee
	0,  // [0:9] is the sub-list for field type_name
}

func init() { file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_init() }
func file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_init() {
	if File_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto != nil {
		return
	}
	file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes[4].OneofWrappers = []any{}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDesc), len(file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   6,
			NumExtensions: 2,
			NumServices:   0,
		},
		GoTypes:           file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_goTypes,
		DependencyIndexes: file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_depIdxs,
		MessageInfos:      file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_msgTypes,
		ExtensionInfos:    file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_extTypes,
	}.Build()
	File_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto = out.File
	file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_goTypes = nil
	file_org_project_planton_provider_kubernetes_kuberneteskafka_v1_spec_proto_depIdxs = nil
}
