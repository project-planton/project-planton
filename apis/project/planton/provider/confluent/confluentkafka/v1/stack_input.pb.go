// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: project/planton/provider/confluent/confluentkafka/v1/stack_input.proto

package confluentkafkav1

import (
	v1 "github.com/project-planton/project-planton/apis/project/planton/credential/confluentcredential/v1"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// confluent-kafka stack-input
type ConfluentKafkaStackInput struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// target cloud-resource
	Target *ConfluentKafka `protobuf:"bytes,1,opt,name=target,proto3" json:"target,omitempty"`
	// provider-credential
	ProviderCredential *v1.ConfluentCredentialSpec `protobuf:"bytes,2,opt,name=provider_credential,json=providerCredential,proto3" json:"provider_credential,omitempty"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *ConfluentKafkaStackInput) Reset() {
	*x = ConfluentKafkaStackInput{}
	mi := &file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConfluentKafkaStackInput) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConfluentKafkaStackInput) ProtoMessage() {}

func (x *ConfluentKafkaStackInput) ProtoReflect() protoreflect.Message {
	mi := &file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConfluentKafkaStackInput.ProtoReflect.Descriptor instead.
func (*ConfluentKafkaStackInput) Descriptor() ([]byte, []int) {
	return file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDescGZIP(), []int{0}
}

func (x *ConfluentKafkaStackInput) GetTarget() *ConfluentKafka {
	if x != nil {
		return x.Target
	}
	return nil
}

func (x *ConfluentKafkaStackInput) GetProviderCredential() *v1.ConfluentCredentialSpec {
	if x != nil {
		return x.ProviderCredential
	}
	return nil
}

var File_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto protoreflect.FileDescriptor

const file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDesc = "" +
	"\n" +
	"Fproject/planton/provider/confluent/confluentkafka/v1/stack_input.proto\x124project.planton.provider.confluent.confluentkafka.v1\x1a<project/planton/credential/confluentcredential/v1/spec.proto\x1a>project/planton/provider/confluent/confluentkafka/v1/api.proto\"\xf5\x01\n" +
	"\x18ConfluentKafkaStackInput\x12\\\n" +
	"\x06target\x18\x01 \x01(\v2D.project.planton.provider.confluent.confluentkafka.v1.ConfluentKafkaR\x06target\x12{\n" +
	"\x13provider_credential\x18\x02 \x01(\v2J.project.planton.credential.confluentcredential.v1.ConfluentCredentialSpecR\x12providerCredentialB\xb9\x03\n" +
	"8com.project.planton.provider.confluent.confluentkafka.v1B\x0fStackInputProtoP\x01Zugithub.com/project-planton/project-planton/apis/project/planton/provider/confluent/confluentkafka/v1;confluentkafkav1\xa2\x02\x05PPPCC\xaa\x024Project.Planton.Provider.Confluent.Confluentkafka.V1\xca\x024Project\\Planton\\Provider\\Confluent\\Confluentkafka\\V1\xe2\x02@Project\\Planton\\Provider\\Confluent\\Confluentkafka\\V1\\GPBMetadata\xea\x029Project::Planton::Provider::Confluent::Confluentkafka::V1b\x06proto3"

var (
	file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDescOnce sync.Once
	file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDescData []byte
)

func file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDescGZIP() []byte {
	file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDescOnce.Do(func() {
		file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDesc), len(file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDesc)))
	})
	return file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDescData
}

var file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_msgTypes = make([]protoimpl.MessageInfo, 1)
var file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_goTypes = []any{
	(*ConfluentKafkaStackInput)(nil),   // 0: project.planton.provider.confluent.confluentkafka.v1.ConfluentKafkaStackInput
	(*ConfluentKafka)(nil),             // 1: project.planton.provider.confluent.confluentkafka.v1.ConfluentKafka
	(*v1.ConfluentCredentialSpec)(nil), // 2: project.planton.credential.confluentcredential.v1.ConfluentCredentialSpec
}
var file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_depIdxs = []int32{
	1, // 0: project.planton.provider.confluent.confluentkafka.v1.ConfluentKafkaStackInput.target:type_name -> project.planton.provider.confluent.confluentkafka.v1.ConfluentKafka
	2, // 1: project.planton.provider.confluent.confluentkafka.v1.ConfluentKafkaStackInput.provider_credential:type_name -> project.planton.credential.confluentcredential.v1.ConfluentCredentialSpec
	2, // [2:2] is the sub-list for method output_type
	2, // [2:2] is the sub-list for method input_type
	2, // [2:2] is the sub-list for extension type_name
	2, // [2:2] is the sub-list for extension extendee
	0, // [0:2] is the sub-list for field type_name
}

func init() { file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_init() }
func file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_init() {
	if File_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto != nil {
		return
	}
	file_project_planton_provider_confluent_confluentkafka_v1_api_proto_init()
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDesc), len(file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   1,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_goTypes,
		DependencyIndexes: file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_depIdxs,
		MessageInfos:      file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_msgTypes,
	}.Build()
	File_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto = out.File
	file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_goTypes = nil
	file_project_planton_provider_confluent_confluentkafka_v1_stack_input_proto_depIdxs = nil
}
