// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: project/planton/provider/kubernetes/kafkakubernetes/v1/spec.proto

package kafkakubernetesv1

import (
	_ "buf.build/gen/go/bufbuild/protovalidate/protocolbuffers/go/buf/validate"
	kubernetes "github.com/project-planton/project-planton/apis/project/planton/shared/kubernetes"
	_ "github.com/project-planton/project-planton/apis/project/planton/shared/options"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	descriptorpb "google.golang.org/protobuf/types/descriptorpb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// **KafkaKubernetesSpec** defines the configuration for deploying Apache Kafka on a Kubernetes cluster.
// This message includes specifications for Kafka topics, broker containers, Zookeeper containers, schema registry,
// ingress settings, and the option to deploy a Kafka UI.
// By configuring these parameters, you can set up a Kafka cluster tailored to your application's needs, including
// resource allocation, data persistence, and external access.
type KafkaKubernetesSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A list of Kafka topics to be created in the Kafka cluster.
	KafkaTopics []*KafkaTopic `protobuf:"bytes,1,rep,name=kafka_topics,json=kafkaTopics,proto3" json:"kafka_topics,omitempty"`
	// The specifications for the Kafka broker containers.
	BrokerContainer *KafkaKubernetesBrokerContainer `protobuf:"bytes,2,opt,name=broker_container,json=brokerContainer,proto3" json:"broker_container,omitempty"`
	// The specifications for the Zookeeper containers.
	ZookeeperContainer *KafkaKubernetesZookeeperContainer `protobuf:"bytes,3,opt,name=zookeeper_container,json=zookeeperContainer,proto3" json:"zookeeper_container,omitempty"`
	// The specifications for the Schema Registry containers.
	SchemaRegistryContainer *KafkaKubernetesSchemaRegistryContainer `protobuf:"bytes,4,opt,name=schema_registry_container,json=schemaRegistryContainer,proto3" json:"schema_registry_container,omitempty"`
	// The ingress configuration for the Kafka deployment.
	Ingress *kubernetes.IngressSpec `protobuf:"bytes,5,opt,name=ingress,proto3" json:"ingress,omitempty"`
	// A flag to toggle the deployment of the Kafka UI component.
	IsDeployKafkaUi bool `protobuf:"varint,6,opt,name=is_deploy_kafka_ui,json=isDeployKafkaUi,proto3" json:"is_deploy_kafka_ui,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *KafkaKubernetesSpec) Reset() {
	*x = KafkaKubernetesSpec{}
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaKubernetesSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaKubernetesSpec) ProtoMessage() {}

func (x *KafkaKubernetesSpec) ProtoReflect() protoreflect.Message {
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaKubernetesSpec.ProtoReflect.Descriptor instead.
func (*KafkaKubernetesSpec) Descriptor() ([]byte, []int) {
	return file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescGZIP(), []int{0}
}

func (x *KafkaKubernetesSpec) GetKafkaTopics() []*KafkaTopic {
	if x != nil {
		return x.KafkaTopics
	}
	return nil
}

func (x *KafkaKubernetesSpec) GetBrokerContainer() *KafkaKubernetesBrokerContainer {
	if x != nil {
		return x.BrokerContainer
	}
	return nil
}

func (x *KafkaKubernetesSpec) GetZookeeperContainer() *KafkaKubernetesZookeeperContainer {
	if x != nil {
		return x.ZookeeperContainer
	}
	return nil
}

func (x *KafkaKubernetesSpec) GetSchemaRegistryContainer() *KafkaKubernetesSchemaRegistryContainer {
	if x != nil {
		return x.SchemaRegistryContainer
	}
	return nil
}

func (x *KafkaKubernetesSpec) GetIngress() *kubernetes.IngressSpec {
	if x != nil {
		return x.Ingress
	}
	return nil
}

func (x *KafkaKubernetesSpec) GetIsDeployKafkaUi() bool {
	if x != nil {
		return x.IsDeployKafkaUi
	}
	return false
}

// **KafkaKubernetesBrokerContainer** specifies the configuration for the Kafka broker containers.
// It includes settings such as the number of replicas, resource allocations, and disk size.
// Proper configuration ensures optimal performance and data reliability for your Kafka brokers.
type KafkaKubernetesBrokerContainer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of Kafka brokers to deploy.
	// Defaults to 1 if the client sets the value to 0.
	// Recommended default value is 1.
	Replicas int32 `protobuf:"varint,1,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// The CPU and memory resources allocated to the Kafka broker containers.
	Resources *kubernetes.ContainerResources `protobuf:"bytes,2,opt,name=resources,proto3" json:"resources,omitempty"`
	// The size of the disk to be attached to each broker instance (e.g., "30Gi").
	// A default value is set if not provided by the client.
	DiskSize      string `protobuf:"bytes,3,opt,name=disk_size,json=diskSize,proto3" json:"disk_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KafkaKubernetesBrokerContainer) Reset() {
	*x = KafkaKubernetesBrokerContainer{}
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaKubernetesBrokerContainer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaKubernetesBrokerContainer) ProtoMessage() {}

func (x *KafkaKubernetesBrokerContainer) ProtoReflect() protoreflect.Message {
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaKubernetesBrokerContainer.ProtoReflect.Descriptor instead.
func (*KafkaKubernetesBrokerContainer) Descriptor() ([]byte, []int) {
	return file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescGZIP(), []int{1}
}

func (x *KafkaKubernetesBrokerContainer) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *KafkaKubernetesBrokerContainer) GetResources() *kubernetes.ContainerResources {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *KafkaKubernetesBrokerContainer) GetDiskSize() string {
	if x != nil {
		return x.DiskSize
	}
	return ""
}

// **KafkaKubernetesZookeeperContainer** specifies the configuration for the Zookeeper containers.
// Zookeeper is required for Kafka cluster management and coordination.
// Proper configuration ensures high availability and reliability of your Kafka cluster.
type KafkaKubernetesZookeeperContainer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of Zookeeper container replicas.
	// Zookeeper requires at least 3 replicas for high availability (HA) mode.
	// Zookeeper uses the Raft consensus algorithm; refer to https://raft.github.io/ for more information on how replica
	// count affects availability.
	Replicas int32 `protobuf:"varint,1,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// The CPU and memory resources allocated to the Zookeeper containers.
	Resources *kubernetes.ContainerResources `protobuf:"bytes,2,opt,name=resources,proto3" json:"resources,omitempty"`
	// The size of the disk to be attached to each Zookeeper instance (e.g., "30Gi").
	// A default value is set if not provided by the client.
	DiskSize      string `protobuf:"bytes,3,opt,name=disk_size,json=diskSize,proto3" json:"disk_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KafkaKubernetesZookeeperContainer) Reset() {
	*x = KafkaKubernetesZookeeperContainer{}
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaKubernetesZookeeperContainer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaKubernetesZookeeperContainer) ProtoMessage() {}

func (x *KafkaKubernetesZookeeperContainer) ProtoReflect() protoreflect.Message {
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaKubernetesZookeeperContainer.ProtoReflect.Descriptor instead.
func (*KafkaKubernetesZookeeperContainer) Descriptor() ([]byte, []int) {
	return file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescGZIP(), []int{2}
}

func (x *KafkaKubernetesZookeeperContainer) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *KafkaKubernetesZookeeperContainer) GetResources() *kubernetes.ContainerResources {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *KafkaKubernetesZookeeperContainer) GetDiskSize() string {
	if x != nil {
		return x.DiskSize
	}
	return ""
}

// **KafkaKubernetesSchemaRegistryContainer** specifies the configuration for the Schema Registry containers.
// The Schema Registry provides a serving layer for your metadata, allowing data producers and consumers to evolve independently.
type KafkaKubernetesSchemaRegistryContainer struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A flag to control whether the Schema Registry is created for the Kafka deployment.
	// Defaults to `false`.
	IsEnabled bool `protobuf:"varint,1,opt,name=is_enabled,json=isEnabled,proto3" json:"is_enabled,omitempty"`
	// The number of Schema Registry replicas.
	// Recommended default value is "1".
	// This value has no effect if `is_enabled` is set to `false`.
	Replicas int32 `protobuf:"varint,2,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// The CPU and memory resources allocated to the Schema Registry containers.
	Resources     *kubernetes.ContainerResources `protobuf:"bytes,3,opt,name=resources,proto3" json:"resources,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KafkaKubernetesSchemaRegistryContainer) Reset() {
	*x = KafkaKubernetesSchemaRegistryContainer{}
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaKubernetesSchemaRegistryContainer) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaKubernetesSchemaRegistryContainer) ProtoMessage() {}

func (x *KafkaKubernetesSchemaRegistryContainer) ProtoReflect() protoreflect.Message {
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaKubernetesSchemaRegistryContainer.ProtoReflect.Descriptor instead.
func (*KafkaKubernetesSchemaRegistryContainer) Descriptor() ([]byte, []int) {
	return file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescGZIP(), []int{3}
}

func (x *KafkaKubernetesSchemaRegistryContainer) GetIsEnabled() bool {
	if x != nil {
		return x.IsEnabled
	}
	return false
}

func (x *KafkaKubernetesSchemaRegistryContainer) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *KafkaKubernetesSchemaRegistryContainer) GetResources() *kubernetes.ContainerResources {
	if x != nil {
		return x.Resources
	}
	return nil
}

// **KafkaTopic** represents a Kafka topic to be created in the Kafka cluster.
// It includes configurations such as the topic name, number of partitions, replicas, and additional configurations.
type KafkaTopic struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the Kafka topic.
	// Must be between 1 and 249 characters in length.
	// The name must start and end with an alphanumeric character, can contain alphanumeric characters, '.', '_', and '-'.
	// Must not contain '..' or non-ASCII characters.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// The number of partitions for the topic.
	// Recommended default is 1.
	Partitions int32 `protobuf:"varint,2,opt,name=partitions,proto3" json:"partitions,omitempty"`
	// The number of replicas for the topic.
	// Recommended default is 1.
	Replicas int32 `protobuf:"varint,3,opt,name=replicas,proto3" json:"replicas,omitempty"`
	// Additional configuration for the Kafka topic.
	// If not provided, default values will be set.
	// For example, the default `delete.policy` is `delete`, but it can be set to `compact`.
	Config        map[string]string `protobuf:"bytes,4,rep,name=config,proto3" json:"config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *KafkaTopic) Reset() {
	*x = KafkaTopic{}
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *KafkaTopic) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*KafkaTopic) ProtoMessage() {}

func (x *KafkaTopic) ProtoReflect() protoreflect.Message {
	mi := &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use KafkaTopic.ProtoReflect.Descriptor instead.
func (*KafkaTopic) Descriptor() ([]byte, []int) {
	return file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescGZIP(), []int{4}
}

func (x *KafkaTopic) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *KafkaTopic) GetPartitions() int32 {
	if x != nil {
		return x.Partitions
	}
	return 0
}

func (x *KafkaTopic) GetReplicas() int32 {
	if x != nil {
		return x.Replicas
	}
	return 0
}

func (x *KafkaTopic) GetConfig() map[string]string {
	if x != nil {
		return x.Config
	}
	return nil
}

var file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_extTypes = []protoimpl.ExtensionInfo{
	{
		ExtendedType:  (*descriptorpb.FieldOptions)(nil),
		ExtensionType: (*KafkaKubernetesBrokerContainer)(nil),
		Field:         524001,
		Name:          "project.planton.provider.kubernetes.kafkakubernetes.v1.default_broker_container",
		Tag:           "bytes,524001,opt,name=default_broker_container",
		Filename:      "project/planton/provider/kubernetes/kafkakubernetes/v1/spec.proto",
	},
	{
		ExtendedType:  (*descriptorpb.FieldOptions)(nil),
		ExtensionType: (*KafkaKubernetesZookeeperContainer)(nil),
		Field:         524002,
		Name:          "project.planton.provider.kubernetes.kafkakubernetes.v1.default_zookeeper_container",
		Tag:           "bytes,524002,opt,name=default_zookeeper_container",
		Filename:      "project/planton/provider/kubernetes/kafkakubernetes/v1/spec.proto",
	},
}

// Extension fields to descriptorpb.FieldOptions.
var (
	// optional project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesBrokerContainer default_broker_container = 524001;
	E_DefaultBrokerContainer = &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_extTypes[0]
	// optional project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesZookeeperContainer default_zookeeper_container = 524002;
	E_DefaultZookeeperContainer = &file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_extTypes[1]
)

var File_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto protoreflect.FileDescriptor

const file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDesc = "" +
	"\n" +
	"Aproject/planton/provider/kubernetes/kafkakubernetes/v1/spec.proto\x126project.planton.provider.kubernetes.kafkakubernetes.v1\x1a\x1bbuf/validate/validate.proto\x1a google/protobuf/descriptor.proto\x1a2project/planton/shared/kubernetes/kubernetes.proto\x1a/project/planton/shared/kubernetes/options.proto\x1a,project/planton/shared/options/options.proto\"\x83\x06\n" +
	"\x13KafkaKubernetesSpec\x12e\n" +
	"\fkafka_topics\x18\x01 \x03(\v2B.project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaTopicR\vkafkaTopics\x12\xad\x01\n" +
	"\x10broker_container\x18\x02 \x01(\v2V.project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesBrokerContainerB*\x8a\xee\xff\x01%\b\x01\x12\x1c\n" +
	"\f\n" +
	"\x051000m\x12\x031Gi\x12\f\n" +
	"\x0350m\x12\x05100Mi\x1a\x031GiR\x0fbrokerContainer\x12\xb6\x01\n" +
	"\x13zookeeper_container\x18\x03 \x01(\v2Y.project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesZookeeperContainerB*\x92\xee\xff\x01%\b\x01\x12\x1c\n" +
	"\f\n" +
	"\x051000m\x12\x031Gi\x12\f\n" +
	"\x0350m\x12\x05100Mi\x1a\x031GiR\x12zookeeperContainer\x12\x9a\x01\n" +
	"\x19schema_registry_container\x18\x04 \x01(\v2^.project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSchemaRegistryContainerR\x17schemaRegistryContainer\x12H\n" +
	"\aingress\x18\x05 \x01(\v2..project.planton.shared.kubernetes.IngressSpecR\aingress\x125\n" +
	"\x12is_deploy_kafka_ui\x18\x06 \x01(\bB\b\x92\xa6\x1d\x04trueR\x0fisDeployKafkaUi\"\xd5\x02\n" +
	"\x1eKafkaKubernetesBrokerContainer\x12\x1a\n" +
	"\breplicas\x18\x01 \x01(\x05R\breplicas\x12S\n" +
	"\tresources\x18\x02 \x01(\v25.project.planton.shared.kubernetes.ContainerResourcesR\tresources\x12\xc1\x01\n" +
	"\tdisk_size\x18\x03 \x01(\tB\xa3\x01\xbaH\x9f\x01\xba\x01\x9b\x01\n" +
	"&spec.broker_container.disk_size.format\x12\x1aDisk size value is invalid\x1aUthis.matches('^\\\\d+(\\\\.\\\\d+)?\\\\s?(Ki|Mi|Gi|Ti|Pi|Ei|K|M|G|T|P|E)$') && size(this) > 0R\bdiskSize\"\xd8\x02\n" +
	"!KafkaKubernetesZookeeperContainer\x12\x1a\n" +
	"\breplicas\x18\x01 \x01(\x05R\breplicas\x12S\n" +
	"\tresources\x18\x02 \x01(\v25.project.planton.shared.kubernetes.ContainerResourcesR\tresources\x12\xc1\x01\n" +
	"\tdisk_size\x18\x03 \x01(\tB\xa3\x01\xbaH\x9f\x01\xba\x01\x9b\x01\n" +
	"&spec.broker_container.disk_size.format\x12\x1aDisk size value is invalid\x1aUthis.matches('^\\\\d+(\\\\.\\\\d+)?\\\\s?(Ki|Mi|Gi|Ti|Pi|Ei|K|M|G|T|P|E)$') && size(this) > 0R\bdiskSize\"\xe2\x01\n" +
	"&KafkaKubernetesSchemaRegistryContainer\x12\x1d\n" +
	"\n" +
	"is_enabled\x18\x01 \x01(\bR\tisEnabled\x12!\n" +
	"\breplicas\x18\x02 \x01(\x05B\x05\x92\xa6\x1d\x011R\breplicas\x12v\n" +
	"\tresources\x18\x03 \x01(\v25.project.planton.shared.kubernetes.ContainerResourcesB!\xba\xfb\xa4\x02\x1c\n" +
	"\f\n" +
	"\x051000m\x12\x031Gi\x12\f\n" +
	"\x0350m\x12\x05100MiR\tresources\"\xb0\b\n" +
	"\n" +
	"KafkaTopic\x12\xdf\x03\n" +
	"\x04name\x18\x01 \x01(\tB\xca\x03\xbaH\xc6\x03\xba\x01Z\n" +
	"\n" +
	"topic.name\x12+Should start with an alphanumeric character\x1a\x1fthis.matches('^[a-zA-Z0-9].*$')\xba\x01p\n" +
	"\n" +
	"topic.name\x12?Only alphanumeric and ('.', '_' and '-') characters are allowed\x1a!this.matches('^[a-zA-Z0-9._-]+$')\xba\x019\n" +
	"\n" +
	"topic.name\x12\x15Must not contain '..'\x1a\x14!this.contains('..')\xba\x01S\n" +
	"\n" +
	"topic.name\x12%Must not contain non-ASCII characters\x1a\x1ethis.matches('^[\\x00-\\x7F]+$')\xba\x01W\n" +
	"\n" +
	"topic.name\x12)Should end with an alphanumeric character\x1a\x1ethis.matches('.*[a-zA-Z0-9]$')\xc8\x01\x01r\x05\x10\x01\x18\xf9\x01R\x04name\x12%\n" +
	"\n" +
	"partitions\x18\x02 \x01(\x05B\x05\x8a\xa6\x1d\x011R\n" +
	"partitions\x12!\n" +
	"\breplicas\x18\x03 \x01(\x05B\x05\x8a\xa6\x1d\x011R\breplicas\x12\xba\x03\n" +
	"\x06config\x18\x04 \x03(\v2N.project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaTopic.ConfigEntryB\xd1\x02\x9a\xa6\x1d\x18\n" +
	"\x0ecleanup.policy\x12\x06delete\x9a\xa6\x1d\x1f\n" +
	"\x13delete.retention.ms\x12\b86400000\x9a\xa6\x1d\x1c\n" +
	"\x11max.message.bytes\x12\a2097164\x9a\xa6\x1d:\n" +
	"#message.timestamp.difference.max.ms\x12\x139223372036854775807\x9a\xa6\x1d$\n" +
	"\x16message.timestamp.type\x12\n" +
	"CreateTime\x9a\xa6\x1d\x18\n" +
	"\x13min.insync.replicas\x12\x011\x9a\xa6\x1d\x15\n" +
	"\x0fretention.bytes\x12\x02-1\x9a\xa6\x1d\x19\n" +
	"\fretention.ms\x12\t604800000\x9a\xa6\x1d\x1b\n" +
	"\rsegment.bytes\x12\n" +
	"1073741824\x9a\xa6\x1d\x17\n" +
	"\n" +
	"segment.ms\x12\t604800000R\x06config\x1a9\n" +
	"\vConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01:\xb1\x01\n" +
	"\x18default_broker_container\x12\x1d.google.protobuf.FieldOptions\x18\xe1\xfd\x1f \x01(\v2V.project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesBrokerContainerR\x16defaultBrokerContainer:\xba\x01\n" +
	"\x1bdefault_zookeeper_container\x12\x1d.google.protobuf.FieldOptions\x18\xe2\xfd\x1f \x01(\v2Y.project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesZookeeperContainerR\x19defaultZookeeperContainerB\xc0\x03\n" +
	":com.project.planton.provider.kubernetes.kafkakubernetes.v1B\tSpecProtoP\x01Zxgithub.com/project-planton/project-planton/apis/project/planton/provider/kubernetes/kafkakubernetes/v1;kafkakubernetesv1\xa2\x02\x05PPPKK\xaa\x026Project.Planton.Provider.Kubernetes.Kafkakubernetes.V1\xca\x026Project\\Planton\\Provider\\Kubernetes\\Kafkakubernetes\\V1\xe2\x02BProject\\Planton\\Provider\\Kubernetes\\Kafkakubernetes\\V1\\GPBMetadata\xea\x02;Project::Planton::Provider::Kubernetes::Kafkakubernetes::V1b\x06proto3"

var (
	file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescOnce sync.Once
	file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescData []byte
)

func file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescGZIP() []byte {
	file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescOnce.Do(func() {
		file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDesc), len(file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDesc)))
	})
	return file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDescData
}

var file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes = make([]protoimpl.MessageInfo, 6)
var file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_goTypes = []any{
	(*KafkaKubernetesSpec)(nil),                    // 0: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSpec
	(*KafkaKubernetesBrokerContainer)(nil),         // 1: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesBrokerContainer
	(*KafkaKubernetesZookeeperContainer)(nil),      // 2: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesZookeeperContainer
	(*KafkaKubernetesSchemaRegistryContainer)(nil), // 3: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSchemaRegistryContainer
	(*KafkaTopic)(nil),                             // 4: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaTopic
	nil,                                            // 5: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaTopic.ConfigEntry
	(*kubernetes.IngressSpec)(nil),                 // 6: project.planton.shared.kubernetes.IngressSpec
	(*kubernetes.ContainerResources)(nil),          // 7: project.planton.shared.kubernetes.ContainerResources
	(*descriptorpb.FieldOptions)(nil),              // 8: google.protobuf.FieldOptions
}
var file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_depIdxs = []int32{
	4,  // 0: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSpec.kafka_topics:type_name -> project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaTopic
	1,  // 1: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSpec.broker_container:type_name -> project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesBrokerContainer
	2,  // 2: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSpec.zookeeper_container:type_name -> project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesZookeeperContainer
	3,  // 3: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSpec.schema_registry_container:type_name -> project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSchemaRegistryContainer
	6,  // 4: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSpec.ingress:type_name -> project.planton.shared.kubernetes.IngressSpec
	7,  // 5: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesBrokerContainer.resources:type_name -> project.planton.shared.kubernetes.ContainerResources
	7,  // 6: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesZookeeperContainer.resources:type_name -> project.planton.shared.kubernetes.ContainerResources
	7,  // 7: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesSchemaRegistryContainer.resources:type_name -> project.planton.shared.kubernetes.ContainerResources
	5,  // 8: project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaTopic.config:type_name -> project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaTopic.ConfigEntry
	8,  // 9: project.planton.provider.kubernetes.kafkakubernetes.v1.default_broker_container:extendee -> google.protobuf.FieldOptions
	8,  // 10: project.planton.provider.kubernetes.kafkakubernetes.v1.default_zookeeper_container:extendee -> google.protobuf.FieldOptions
	1,  // 11: project.planton.provider.kubernetes.kafkakubernetes.v1.default_broker_container:type_name -> project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesBrokerContainer
	2,  // 12: project.planton.provider.kubernetes.kafkakubernetes.v1.default_zookeeper_container:type_name -> project.planton.provider.kubernetes.kafkakubernetes.v1.KafkaKubernetesZookeeperContainer
	13, // [13:13] is the sub-list for method output_type
	13, // [13:13] is the sub-list for method input_type
	11, // [11:13] is the sub-list for extension type_name
	9,  // [9:11] is the sub-list for extension extendee
	0,  // [0:9] is the sub-list for field type_name
}

func init() { file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_init() }
func file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_init() {
	if File_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDesc), len(file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   6,
			NumExtensions: 2,
			NumServices:   0,
		},
		GoTypes:           file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_goTypes,
		DependencyIndexes: file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_depIdxs,
		MessageInfos:      file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_msgTypes,
		ExtensionInfos:    file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_extTypes,
	}.Build()
	File_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto = out.File
	file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_goTypes = nil
	file_project_planton_provider_kubernetes_kafkakubernetes_v1_spec_proto_depIdxs = nil
}
